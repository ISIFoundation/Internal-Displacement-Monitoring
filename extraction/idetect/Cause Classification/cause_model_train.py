# -*- coding: utf-8 -*-
"""Copy of Cause.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YkZaY-SJdzniITUFc--XlXwW0uPVt2sM
"""

from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np
import pandas as pd
from collections import Counter
import nltk
nltk.download('stopwords')
nltk.download('wordnet')
from nltk.stem import WordNetLemmatizer 
import re 
from nltk.corpus import stopwords


class Cause_Classification(object): 

    def __init__(self, train_df, model):
        self.train_df = train_df
        self.tfidf = TfidfVectorizer(sublinear_tf=True,
                            analyzer='word', ngram_range=(1, 4), 
                            min_df = 1, stop_words='english',norm='l2')
        self.model = model
        self.lemmatizer = WordNetLemmatizer()
    
    def text_basic_clean(self, text):
        text = text.replace('\n\nâ€¢', '').replace('\n\n', '')
        text = re.sub(r'[^\w\s]', '', text) 
        text = text.replace('  ', ' ')
        text = ' '.join([self.lemmatizer.lemmatize(word.lower()) for word in text.split() if word not in stopwords.words('english') and word.isalpha()])
        return text 
    
    def deduplicate_label(self, df):
        result = [] 
        for id in df['id'].unique():
            curr_df = df[(df['id'] == id)]
            if len(curr_df['value'].unique()) == 1:
                result.append(curr_df['value'].unique()[0])
            ### Take the majority vote for each document
            else:
                if (Counter(curr_df.value).most_common()[0][1] == Counter(curr_df.value).most_common()[1][1]):
                    if (Counter(curr_df.value).most_common()[0][0] == "CONFLICT") or (Counter(curr_df.value).most_common()[0][0] == "DISASTER"):
                        result.append(Counter(curr_df.value).most_common()[0][0])
                    elif (Counter(curr_df.value).most_common()[1][0] == "CONFLICT") or (Counter(curr_df.value).most_common()[1][0] == "DISASTER"):
                        result.append(Counter(curr_df.value).most_common()[1][0])
                else:
                    result.append(Counter(curr_df.value).most_common()[0][0])                
        return result

    def label_mapping(self, label):
        if label == "CONFLICT":
            return 0
        elif label == "DISASTER":
            return 1  

    def data_Preprocessing(self):
        df = self.train_df 
        df['text3'] = df['text'].apply(lambda x: self.text_basic_clean(x)) 
        cause_data = df[['id', 'labeler','value', 'text3']].reset_index(drop = True)
        cause_data2 = cause_data[['id', 'text3']].drop_duplicates().reset_index(drop = True)
        cause_data2['label'] = self.deduplicate_label(cause_data)
        cause_data2 = cause_data2[(cause_data2['label'] != 'OTHER_CAUSE')].reset_index(drop = True)
        cause_data2['label'] = cause_data2['label'].apply(lambda x: self.label_mapping(x)) 
        return cause_data2

    def get_embeddings(self, texts):
        tfidf_matrix = self.tfidf.fit_transform(texts).toarray()
        return tfidf_matrix

    def fit(self):
        cause_data = self.data_Preprocessing()
        tfidf_matrix, y_train = self.get_embeddings(list(cause_data.text3)), np.array(cause_data.label)
        fitted_model = self.model.fit(tfidf_matrix, y_train)
        return fitted_model

    def predict_proba(self, test_text):
        model = self.fit()
        if type(test_text) == str:
            test_texts = [test_text]
        test_texts = [self.text_basic_clean(x) for x in test_texts]
        x_test = self.tfidf.transform(test_texts)
        prob = model.predict_proba(x_test)
        if type(test_text) == str:
            return prob[0]
        return prob
      

    def predict(self, test_text):
        model = self.fit()
        if type(test_text) == str:
            test_texts = [test_text]
        test_texts = [self.text_basic_clean(x) for x in test_texts]
        x_test = self.tfidf.transform(test_texts)
        label = model.predict(x_test)
        if type(test_text) == str:
            return label[0]
        return label

