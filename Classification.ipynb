{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/panisson/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/panisson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords');\n",
    "nltk.download('wordnet');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate classification models\n",
    "\n",
    "This notebook is used to load data for the classification task and evaluate different classification models.\n",
    "\n",
    "Before loading the content, you must run the notebook Data-Preparation.ipynb to scrape articles not shared with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = pd.read_csv('data/assets_scraped.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare data for the Type classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_df_nocontent = pd.read_csv('data/type_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_df = pd.merge(type_df_nocontent, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def text_basic_clean(text):\n",
    "    text = text.replace('\\n\\n•', '').replace('\\n\\n', '')\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) \n",
    "    text = text.replace('  ', ' ')\n",
    "    text = ' '.join([lemmatizer.lemmatize(word.lower())\n",
    "                     for word in text.split()\n",
    "                     if word not in stopwords.words('english') and word.isalpha()])\n",
    "    return text\n",
    "\n",
    "type_df['content_clean'] = type_df['content'].apply(lambda x: text_basic_clean(x))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester():\n",
    "    \n",
    "    def __init__(self, model, param_grid={}):\n",
    "        self.model = model\n",
    "        self.param_grid = param_grid\n",
    "        self.tfidf = TfidfVectorizer(sublinear_tf=True,\n",
    "                            analyzer='word', ngram_range=(1, 4), \n",
    "                            min_df = 5, stop_words='english',norm='l2')\n",
    "    \n",
    "    def run_val_test(self, seed):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=seed, stratify = y)\n",
    "\n",
    "        tfidf_matrix = self.tfidf.fit_transform(X_train).toarray()\n",
    "        x_test = self.tfidf.transform(X_test).toarray()\n",
    "        cv = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=seed)\n",
    "        gs = GridSearchCV(self.model, param_grid=self.param_grid,\n",
    "                          cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "        gs.fit(tfidf_matrix, y_train)\n",
    "        if hasattr(gs, \"predict_proba\"):\n",
    "            predicted_prob = gs.predict_proba(x_test)[:,1]\n",
    "        else:\n",
    "            predicted_prob = gs.decision_function(x_test)\n",
    "        \n",
    "        \n",
    "        return gs.best_score_, metrics.roc_auc_score(y_test, predicted_prob)\n",
    "    \n",
    "    def run_many(self, n_runs=50):\n",
    "        val_scores = []\n",
    "        test_scores = []\n",
    "        for seed in tqdm(range(n_runs), file=sys.stdout):\n",
    "            val_score, test_score = self.run_val_test(seed)\n",
    "            val_scores.append(val_score)\n",
    "            test_scores.append(test_score)\n",
    "        return val_scores, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_model():\n",
    "    xgb_clf = xgb.XGBClassifier(use_label_encoder=False)\n",
    "    args = {'learning_rate': 0.3, 'colsample_bytree': 0.8, 'scale_pos_weight': 3, \n",
    "            'n_jobs': 10, 'n_estimators': 300, 'max_depth': 8, 'subsample': 0.8, 'verbosity': 0}\n",
    "    return xgb_clf.set_params(**args)\n",
    "\n",
    "def get_rf():\n",
    "    rf = RandomForestClassifier(min_samples_leaf = 5, \n",
    "                                n_estimators = 200,\n",
    "                                class_weight = 'balanced_subsample',\n",
    "                                criterion = 'gini',\n",
    "                                random_state = 42)\n",
    "    return rf\n",
    "\n",
    "lr_model = LogisticRegression(penalty='l2', C=0.1, class_weight='balanced', solver='liblinear')\n",
    "svm_model = SVC(kernel='rbf', class_weight='balanced', gamma='auto')\n",
    "\n",
    "models = [\n",
    "    ('Multinomial Naive Bayes', MultinomialNB(), {'alpha': [0.5, 1, 1.5]}),\n",
    "    ('XGBoost', xgb_model(), {'max_depth': [3,4,5], 'n_estimators': [10, 20]}),\n",
    "    ('Random Forest', get_rf(), {'min_samples_leaf': [3,4,5,6]}),\n",
    "    ('Logistic Regression', lr_model, {'C': [0.1, 1, 2]}),\n",
    "    ('Support Vector Machine', svm_model, {'C': [0.1, 1, 2]})\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1: [Both & News] v.s. Summary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(type_df.content_clean)\n",
    "y = np.array(type_df.value.map(lambda x: 0 if x=='SUMMARY' else 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model Multinomial Naive Bayes\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.09it/s]\n",
      "[0.6515000000000001, 0.6214285714285714]\n",
      "Testing model XGBoost\n",
      "100%|██████████| 50/50 [01:07<00:00,  1.35s/it]\n",
      "[0.6309791666666665, 0.6054285714285714]\n",
      "Testing model Random Forest\n",
      "100%|██████████| 50/50 [00:52<00:00,  1.06s/it]\n",
      "[0.6478333333333333, 0.6165714285714285]\n",
      "Testing model Logistic Regression\n",
      "100%|██████████| 50/50 [00:13<00:00,  3.78it/s]\n",
      "[0.6411666666666666, 0.6182857142857143]\n",
      "Testing model Support Vector Machine\n",
      "100%|██████████| 50/50 [00:13<00:00,  3.61it/s]\n",
      "[0.6434583333333334, 0.6231428571428572]\n"
     ]
    }
   ],
   "source": [
    "results_scenario1 = {}\n",
    "for name, model, param_grid in models:\n",
    "    print('Testing model', name)\n",
    "    tester = Tester(model, param_grid)\n",
    "    results_scenario1[name] = tester.run_many()\n",
    "    print([np.mean(r) for r in results_scenario1[name]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>0.651500</td>\n",
       "      <td>0.621429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.630979</td>\n",
       "      <td>0.605429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.647833</td>\n",
       "      <td>0.616571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.641167</td>\n",
       "      <td>0.618286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.643458</td>\n",
       "      <td>0.623143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Validation      Test\n",
       "Multinomial Naive Bayes    0.651500  0.621429\n",
       "XGBoost                    0.630979  0.605429\n",
       "Random Forest              0.647833  0.616571\n",
       "Logistic Regression        0.641167  0.618286\n",
       "Support Vector Machine     0.643458  0.623143"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({k: [np.mean(v[0]), np.mean(v[1])]\n",
    "              for (k,v) in results_scenario1.items()}, index=['Validation', 'Test']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: [Both & Summary] v.s. News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(type_df.content_clean)\n",
    "y = np.array(type_df.value.map(lambda x: 0 if x=='NEWS' else 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model Multinomial Naive Bayes\n",
      "100%|██████████| 50/50 [00:12<00:00,  3.93it/s]\n",
      "[0.6658909090909091, 0.6414285714285713]\n",
      "Testing model XGBoost\n",
      "100%|██████████| 50/50 [01:05<00:00,  1.31s/it]\n",
      "[0.6629272727272728, 0.6610714285714286]\n",
      "Testing model Random Forest\n",
      "100%|██████████| 50/50 [00:53<00:00,  1.06s/it]\n",
      "[0.7040363636363637, 0.6919047619047618]\n",
      "Testing model Logistic Regression\n",
      "100%|██████████| 50/50 [00:12<00:00,  3.86it/s]\n",
      "[0.6609090909090909, 0.6340476190476191]\n",
      "Testing model Support Vector Machine\n",
      "100%|██████████| 50/50 [00:13<00:00,  3.62it/s]\n",
      "[0.6628000000000002, 0.6369047619047619]\n"
     ]
    }
   ],
   "source": [
    "results_scenario2 = {}\n",
    "for name, model, param_grid in models:\n",
    "    print('Testing model', name)\n",
    "    tester = Tester(model, param_grid)\n",
    "    results_scenario2[name] = tester.run_many()\n",
    "    print([np.mean(r) for r in results_scenario2[name]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>0.665891</td>\n",
       "      <td>0.641429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.662927</td>\n",
       "      <td>0.661071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.704036</td>\n",
       "      <td>0.691905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.660909</td>\n",
       "      <td>0.634048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.662800</td>\n",
       "      <td>0.636905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Validation      Test\n",
       "Multinomial Naive Bayes    0.665891  0.641429\n",
       "XGBoost                    0.662927  0.661071\n",
       "Random Forest              0.704036  0.691905\n",
       "Logistic Regression        0.660909  0.634048\n",
       "Support Vector Machine     0.662800  0.636905"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({k: [np.mean(v[0]), np.mean(v[1])]\n",
    "              for (k,v) in results_scenario2.items()}, index=['Validation', 'Test']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Senario 3: News v.s. Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_df2 = type_df.copy()\n",
    "type_df2 = type_df2[type_df2.value != 'BOTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(type_df2.content_clean)\n",
    "y = np.array(type_df2.value.map(lambda x: 0 if x=='SUMMARY' else 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model Multinomial Naive Bayes\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.24it/s]\n",
      "[0.65455, 0.6384615384615384]\n",
      "Testing model XGBoost\n",
      "100%|██████████| 50/50 [00:47<00:00,  1.05it/s]\n",
      "[0.6019, 0.612]\n",
      "Testing model Random Forest\n",
      "100%|██████████| 50/50 [00:43<00:00,  1.14it/s]\n",
      "[0.6459, 0.6873846153846155]\n",
      "Testing model Logistic Regression\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.14it/s]\n",
      "[0.63885, 0.6418461538461538]\n",
      "Testing model Support Vector Machine\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.75it/s]\n",
      "[0.6416499999999999, 0.6467692307692309]\n"
     ]
    }
   ],
   "source": [
    "results_scenario3 = {}\n",
    "for name, model, param_grid in models:\n",
    "    print('Testing model', name)\n",
    "    tester = Tester(model)\n",
    "    results_scenario3[name] = tester.run_many()\n",
    "    print([np.mean(r) for r in results_scenario3[name]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>0.65455</td>\n",
       "      <td>0.638462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.60190</td>\n",
       "      <td>0.612000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.64590</td>\n",
       "      <td>0.687385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.63885</td>\n",
       "      <td>0.641846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.64165</td>\n",
       "      <td>0.646769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         validation      test\n",
       "Multinomial Naive Bayes     0.65455  0.638462\n",
       "XGBoost                     0.60190  0.612000\n",
       "Random Forest               0.64590  0.687385\n",
       "Logistic Regression         0.63885  0.641846\n",
       "Support Vector Machine      0.64165  0.646769"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({k: [np.mean(v[0]), np.mean(v[1])]\n",
    "              for (k,v) in results_scenario3.items()}, index=['validation', 'test']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevance Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_df_nocontent = pd.read_csv('data/relevance_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_df = pd.merge(relevance_df_nocontent, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'RELEVANT': 91, 'NOT_RELEVANT': 102})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(relevance_df.relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>relevance</th>\n",
       "      <th>document_identifier</th>\n",
       "      <th>content</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EN2652359</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>https://reliefweb.int/report/democratic-republ...</td>\n",
       "      <td>SITUATION\\n\\n• More than 13 million people in ...</td>\n",
       "      <td>2019-06-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EN2422390</td>\n",
       "      <td>NOT_RELEVANT</td>\n",
       "      <td>https://www.irishexaminer.com/breakingnews/ire...</td>\n",
       "      <td>Latest: Detectives investigating a car bomb ex...</td>\n",
       "      <td>2019-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EN2718256</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>https://reliefweb.int/report/iraq/iraq-iom-eng...</td>\n",
       "      <td>Baghdad – Across Iraq, the instability and ins...</td>\n",
       "      <td>2019-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EN2460270</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>https://themedialine.org/student-journalists/l...</td>\n",
       "      <td>Experts concerned that some 1.5 million refuge...</td>\n",
       "      <td>2019-02-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EN2845164</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>https://www.theledger.com/news/20191013/syrias...</td>\n",
       "      <td>AKCAKALE, Turkey — Syria's Kurds said Syrian g...</td>\n",
       "      <td>2019-10-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     relevance                                document_identifier  \\\n",
       "0  EN2652359      RELEVANT  https://reliefweb.int/report/democratic-republ...   \n",
       "1  EN2422390  NOT_RELEVANT  https://www.irishexaminer.com/breakingnews/ire...   \n",
       "2  EN2718256      RELEVANT  https://reliefweb.int/report/iraq/iraq-iom-eng...   \n",
       "3  EN2460270      RELEVANT  https://themedialine.org/student-journalists/l...   \n",
       "4  EN2845164      RELEVANT  https://www.theledger.com/news/20191013/syrias...   \n",
       "\n",
       "                                             content     created  \n",
       "0  SITUATION\\n\\n• More than 13 million people in ...  2019-06-24  \n",
       "1  Latest: Detectives investigating a car bomb ex...  2019-01-20  \n",
       "2  Baghdad – Across Iraq, the instability and ins...  2019-08-02  \n",
       "3  Experts concerned that some 1.5 million refuge...  2019-02-23  \n",
       "4  AKCAKALE, Turkey — Syria's Kurds said Syrian g...  2019-10-14  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "import re \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def text_basic_clean(text):\n",
    "    text = text.replace('\\n\\n•', '').replace('\\n\\n', '')\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) \n",
    "    text = text.replace('  ', ' ')\n",
    "    text = ' '.join([lemmatizer.lemmatize(word.lower()) \n",
    "                     for word in text.split() \n",
    "                     if word not in stopwords.words('english') and word.isalpha()])\n",
    "    return text\n",
    "\n",
    "relevance_df['content_clean'] = relevance_df['content'].apply(lambda x: text_basic_clean(x))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(relevance_df.content_clean)\n",
    "y = np.array(relevance_df.relevance.map(lambda x: 0 if x=='NOT_RELEVANT' else 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model Multinomial Naive Bayes\n",
      "100%|██████████| 50/50 [00:22<00:00,  2.25it/s]\n",
      "[0.8272583333333334, 0.8225925925925925]\n",
      "Testing model XGBoost\n",
      "100%|██████████| 50/50 [01:48<00:00,  2.17s/it]\n",
      "[0.7562416666666667, 0.7741798941798943]\n",
      "Testing model Random Forest\n",
      "100%|██████████| 50/50 [01:04<00:00,  1.29s/it]\n",
      "[0.8129333333333335, 0.8252380952380952]\n",
      "Testing model Logistic Regression\n",
      "100%|██████████| 50/50 [00:26<00:00,  1.86it/s]\n",
      "[0.8297374999999999, 0.8291005291005292]\n",
      "Testing model Support Vector Machine\n",
      "100%|██████████| 50/50 [00:36<00:00,  1.38it/s]\n",
      "[0.828475, 0.8267724867724869]\n"
     ]
    }
   ],
   "source": [
    "results_relevance = {}\n",
    "for name, model, param_grid in models:\n",
    "    print('Testing model', name)\n",
    "    tester = Tester(model)\n",
    "    results_relevance[name] = tester.run_many()\n",
    "    print([np.mean(r) for r in results_relevance[name]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>0.827258</td>\n",
       "      <td>0.822593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.756242</td>\n",
       "      <td>0.774180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.812933</td>\n",
       "      <td>0.825238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.829737</td>\n",
       "      <td>0.829101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.828475</td>\n",
       "      <td>0.826772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         validation      test\n",
       "Multinomial Naive Bayes    0.827258  0.822593\n",
       "XGBoost                    0.756242  0.774180\n",
       "Random Forest              0.812933  0.825238\n",
       "Logistic Regression        0.829737  0.829101\n",
       "Support Vector Machine     0.828475  0.826772"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({k: [np.mean(v[0]), np.mean(v[1])]\n",
    "              for (k,v) in results_relevance.items()}, index=['validation', 'test']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
