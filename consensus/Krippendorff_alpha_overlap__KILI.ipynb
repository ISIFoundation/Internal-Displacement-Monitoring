{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expert dataset (Kili)\n",
    "\n",
    "# Define function and metrics for computing Krippendorff's alpha on processed Kili output\n",
    "\n",
    "#### Note that K's alpha measures disagreement, not agreement.\n",
    "#### Final score between 0 and 1 (but can also be negative), where 1 = full reliability (and no disagreement)\n",
    "\n",
    "Alpha is computed on LABELS only (classification part of each task), then on position index OVERLAP (entity extraction part of each task), then on OVERLAP + text SIMILARITY (to cover cases where the labeled texts are similar but not overlapping). Finally the function eval_metric merges everything into one.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>EN2652359</td>\n",
       "      <td>EN2652359</td>\n",
       "      <td>EN2652359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>published</th>\n",
       "      <td>(2019, 6, 24, 'MON')</td>\n",
       "      <td>(2019, 6, 24, 'MON')</td>\n",
       "      <td>(2019, 6, 24, 'MON')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labeler</th>\n",
       "      <td>Fabio Poletto</td>\n",
       "      <td>Fabio Poletto</td>\n",
       "      <td>Fabio Poletto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taskID</th>\n",
       "      <td>TYPE</td>\n",
       "      <td>FACT</td>\n",
       "      <td>FACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>SUMMARY</td>\n",
       "      <td>RETURN</td>\n",
       "      <td>REFUGEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset_from</th>\n",
       "      <td>NaN</td>\n",
       "      <td>636.0</td>\n",
       "      <td>636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset_to</th>\n",
       "      <td>NaN</td>\n",
       "      <td>885.0</td>\n",
       "      <td>885.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Refugees and Congolese returnees from elsewher...</td>\n",
       "      <td>Refugees and Congolese returnees from elsewher...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0  \\\n",
       "id                      EN2652359   \n",
       "published    (2019, 6, 24, 'MON')   \n",
       "labeler             Fabio Poletto   \n",
       "taskID                       TYPE   \n",
       "value                     SUMMARY   \n",
       "offset_from                   NaN   \n",
       "offset_to                     NaN   \n",
       "content                       NaN   \n",
       "\n",
       "                                                             1  \\\n",
       "id                                                   EN2652359   \n",
       "published                                 (2019, 6, 24, 'MON')   \n",
       "labeler                                          Fabio Poletto   \n",
       "taskID                                                    FACT   \n",
       "value                                                   RETURN   \n",
       "offset_from                                              636.0   \n",
       "offset_to                                                885.0   \n",
       "content      Refugees and Congolese returnees from elsewher...   \n",
       "\n",
       "                                                             2  \n",
       "id                                                   EN2652359  \n",
       "published                                 (2019, 6, 24, 'MON')  \n",
       "labeler                                          Fabio Poletto  \n",
       "taskID                                                    FACT  \n",
       "value                                                  REFUGEE  \n",
       "offset_from                                              636.0  \n",
       "offset_to                                                885.0  \n",
       "content      Refugees and Congolese returnees from elsewher...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kilidata = pd.read_csv('../data/Kili/complete_en.csv')\n",
    "kilidata.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kilidata.id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOCATION_ORIGIN    280\n",
       "FACT               270\n",
       "CAUSE              251\n",
       "QUANTITY           232\n",
       "TYPE               133\n",
       "DATE                61\n",
       "Name: taskID, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kilidata.taskID.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Krippendorf's alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define metrics for agreement on each task\n",
    "    \n",
    "def nominal_metric(a, b):\n",
    "    return a != b\n",
    "\n",
    "\n",
    "def interval_metric(a, b):\n",
    "    return (a-b)**2\n",
    "\n",
    "\n",
    "def ratio_metric(a, b):\n",
    "    return ((a-b)/(a+b))**2\n",
    "\n",
    "\n",
    "def type_metric_str(a, b):\n",
    "    (a,b) = sorted((a,b))\n",
    "    if a==b:\n",
    "        return 0        # 0:agreement \n",
    "    elif a=='BOTH' and b=='NEWS': # news and both are same\n",
    "        return 0\n",
    "    elif a=='BOTH' and b=='SUMMARY': # summary and both are same\n",
    "        return 0\n",
    "    else:\n",
    "        return 1        # 1:disagreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def krippendorff_alpha(units, metric=interval_metric):\n",
    "\n",
    "    n = sum(len(pv) for pv in units.values())  # number of pairable values\n",
    "    print (f'n: {n}')\n",
    "    \n",
    "    if n == 0:\n",
    "        raise ValueError(\"No items to compare.\")\n",
    "    \n",
    "    Do = 0.\n",
    "    for grades in units.values():\n",
    "        Du = sum(metric(gi, gj) for gi in grades for gj in grades)\n",
    "        Do += Du/float(len(grades)-1)\n",
    "    Do /= float(n)\n",
    "    print (f'Do: {Do}')\n",
    "\n",
    "    if Do == 0:\n",
    "        return 1.\n",
    "\n",
    "    De = 0.\n",
    "    for g1 in units.values():\n",
    "        for g2 in units.values():\n",
    "            De += sum(metric(gi, gj) for gi in g1 for gj in g2)\n",
    "    De /= float(n*(n-1))\n",
    "    print (f'De: {De}')\n",
    "\n",
    "    return 1.-Do/De if (Do and De) else 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each task, prepare data for computing alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "EN2433725             [NEWS, NEWS, NEWS]\n",
       "EN2434557             [NEWS, NEWS, NEWS]\n",
       "EN2445660                   [NEWS, NEWS]\n",
       "EN2468666        [N_A, SUMMARY, SUMMARY]\n",
       "EN2469866    [SUMMARY, SUMMARY, SUMMARY]\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create assetID-labels table for a given task \n",
    "df_type = kilidata[kilidata.taskID == 'TYPE'][['id', 'labeler', 'value']]\n",
    "df_type = df_type.groupby(['id', 'labeler']).last().reset_index()\n",
    "\n",
    "units = df_type.groupby('id').apply(lambda x: x.value.values)\n",
    "units_type = units[units.map(lambda x: len(x)>1)]\n",
    "units_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 58\n",
      "Do: 0.1724137931034483\n",
      "De: 0.45977011494252873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "krippendorff_alpha(units_type.to_dict(), type_metric_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute alpha for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['TYPE', 'FACT', 'CAUSE', 'QUANTITY', 'LOCATION_ORIGIN', 'DATE']\n",
    "\n",
    "units_dict = {}\n",
    "for task in tasks:\n",
    "    df_task = kilidata[kilidata.taskID == task][['id', 'labeler', 'value']] # select relevant columns\n",
    "    df_task = df_task.groupby(['id', 'labeler']).last().reset_index() # group by 'id' (asset id), 'labeler'\n",
    "\n",
    "    units = df_task.groupby('id').apply(lambda x: x.value.values) # group by 'id' (asset id) and get values (labels)\n",
    "    units = units[units.map(lambda x: len(x)>1)] # keep only asset with > 1 annotation\n",
    "    units_dict[task] = units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 58\n",
      "Do: 0.1724137931034483\n",
      "De: 0.45977011494252873\n",
      "n: 42\n",
      "Do: 0.42857142857142855\n",
      "De: 0.7328687572590011\n",
      "n: 40\n",
      "Do: 0.1\n",
      "De: 0.4564102564102564\n",
      "n: 40\n",
      "Do: 0.15\n",
      "De: 0.18846153846153846\n",
      "n: 39\n",
      "Do: 0.717948717948718\n",
      "De: 0.7004048582995951\n",
      "n: 9\n",
      "Do: 0.2222222222222222\n",
      "De: 0.3888888888888889\n"
     ]
    }
   ],
   "source": [
    "metrics = {'TYPE': type_metric_str,\n",
    "           'FACT':nominal_metric,\n",
    "           'CAUSE':nominal_metric,\n",
    "           'QUANTITY':nominal_metric,\n",
    "           'LOCATION_ORIGIN':nominal_metric,\n",
    "           'DATE':nominal_metric\n",
    "           # 'DATE':(lambda x,y: 0)\n",
    "          }\n",
    "\n",
    "kalphas = {}\n",
    "# for each task return n (number of pairable items), Do (observed disagreement) and De (expected disagreement) \n",
    "for task in tasks:\n",
    "    ka = krippendorff_alpha(units_dict[task].to_dict(), metrics[task]) \n",
    "    kalphas[task] = ka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TYPE': 0.625,\n",
       " 'FACT': 0.41521394611727414,\n",
       " 'CAUSE': 0.7808988764044944,\n",
       " 'QUANTITY': 0.20408163265306123,\n",
       " 'LOCATION_ORIGIN': -0.025048169556840083,\n",
       " 'DATE': 0.4285714285714286}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kalphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TYPE': 0.625,\n",
       " 'FACT': 0.41521394611727414,\n",
       " 'CAUSE': 0.7808988764044944,\n",
       " 'QUANTITY': 0.20408163265306123,\n",
       " 'LOCATION_ORIGIN': -0.025048169556840083,\n",
       " 'DATE': 0.4285714285714286}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kalphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute alpha for text overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for overlap agreement on text selection (offset_from, offset_to)\n",
    "def getOverlap(a, b):\n",
    "    return max(0, min(a[1], b[1]) - max(a[0], b[0]))\n",
    "\n",
    "def getUnion(a, b):\n",
    "    return max(0, max(a[1], b[1]) - min(a[0], b[0]))\n",
    "\n",
    "def textoverlap_metric(a, b):\n",
    "    '''Compute agreement between two labelers (a, b)\n",
    "    as the relative overlap (overlap/union) of the text they selected\n",
    "    '''\n",
    "    (l1_from, l1_to), (l2_from, l2_to) = a, b\n",
    "    o = getOverlap((l1_from, l1_to), (l2_from, l2_to))\n",
    "    u = getUnion((l1_from, l1_to), (l2_from, l2_to))\n",
    "    \n",
    "    aou = 0 if u==0 else o/u\n",
    "    return 0 if aou > 0 else 1\n",
    "\n",
    "def group_offsets(subgroup):\n",
    "    offsets = []\n",
    "    for ix, row in subgroup.iterrows():\n",
    "        offsets.append((row['offset_from'], row['offset_to']))\n",
    "    return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "tasks = ['FACT', 'CAUSE', 'QUANTITY', 'LOCATION_ORIGIN', 'DATE']\n",
    "\n",
    "units_dict = {}\n",
    "for task in tasks:\n",
    "    df_task = kilidata[kilidata.taskID == task][['id', 'labeler', 'value', 'offset_from', 'offset_to']]\n",
    "    df_task = df_task.groupby(['id', 'labeler']).last().reset_index()\n",
    "\n",
    "    units = df_task.groupby('id').apply(group_offsets)\n",
    "    units = units[units.map(lambda x: len(x)>1)]\n",
    "    units_dict[task] = units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 42\n",
      "Do: 0.42857142857142855\n",
      "De: 0.9279907084785134\n",
      "n: 40\n",
      "Do: 0.625\n",
      "De: 0.9769230769230769\n",
      "n: 40\n",
      "Do: 0.45\n",
      "De: 0.9730769230769231\n",
      "n: 39\n",
      "Do: 0.5897435897435898\n",
      "De: 0.97165991902834\n",
      "n: 9\n",
      "Do: 0.8888888888888888\n",
      "De: 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "kalphas_overlap = {}\n",
    "for task in tasks:\n",
    "    ka = krippendorff_alpha(units_dict[task].to_dict(), textoverlap_metric)\n",
    "    kalphas_overlap[task] = ka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FACT': 0.5381727158948686,\n",
       " 'CAUSE': 0.36023622047244097,\n",
       " 'QUANTITY': 0.5375494071146245,\n",
       " 'LOCATION_ORIGIN': 0.3930555555555555,\n",
       " 'DATE': 0.08571428571428574}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print Krippendorff's alpha score based on text selection overlap + text similarity\n",
    "# for a given label and for each NER task\n",
    "kalphas_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute alpha for text overlap + text similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textoverlap(a, b):\n",
    "    '''Compute agreement between two labelers (a, b)\n",
    "    as the relative overlap (overlap/union) of the text they selected\n",
    "    '''\n",
    "    (l1_from, l1_to), (l2_from, l2_to) = a, b\n",
    "    o = getOverlap((l1_from, l1_to), (l2_from, l2_to))\n",
    "    u = getUnion((l1_from, l1_to), (l2_from, l2_to))\n",
    "    \n",
    "    aou = 0 if u==0 else o/u\n",
    "    return aou\n",
    "#    return 0 if aou > 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a distance between a and b, based on overlap and jaccard\n",
    "\n",
    "def text_similarity_metric(a, b, overlap_threshold=0, jaccard_threshold=0):\n",
    "    '''Compute agreement between two labelers (a, b)\n",
    "    as the relative overlap (overlap/union) of the text they selected\n",
    "    PLUS the Jaccard similarity between the two selected texts,\n",
    "    regardless of their position.\n",
    "    \n",
    "    a, b = lists containing values from columns \"offset_from\", \"offset_to\", \"content\"\n",
    "    overlap_threshold = how much overlap is needed for agreement\n",
    "    jaccard_threshold = how much similarity is needed for agreement if no overlap\n",
    "    '''\n",
    "    (l1_from, l1_to, content1), (l2_from, l2_to, content2) = a, b\n",
    "    om = textoverlap((l1_from, l1_to), (l2_from, l2_to))\n",
    "    #if om == 0:\n",
    "    #    return 0\n",
    "    if om > overlap_threshold:\n",
    "        return 0\n",
    "    \n",
    "    # TEXT PREPROCESSING: lowercase, tokenize, remove stopwords\n",
    "     \n",
    "    s1 = tokenizer.tokenize(content1.lower())\n",
    "    s2 = tokenizer.tokenize(content2.lower())\n",
    "    s1 = set([w for w in s1 if not w in stop_words]) \n",
    "    s2 = set([w for w in s2 if not w in stop_words]) \n",
    "    \n",
    "    jaccard = len(s1.intersection(s2))/len(s1.union(s2))\n",
    "    if jaccard > jaccard_threshold:\n",
    "        return 0\n",
    "    \n",
    "    return 1\n",
    "\n",
    "\n",
    "def group_offsets(subgroup):\n",
    "    offsets = []\n",
    "    for ix, row in subgroup.iterrows():\n",
    "        offsets.append((row['offset_from'], row['offset_to'], row['content']))\n",
    "    return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['FACT', 'CAUSE', 'QUANTITY', 'LOCATION_ORIGIN', 'DATE']\n",
    "\n",
    "units_dict = {}\n",
    "for task in tasks:\n",
    "    df_task = kilidata[kilidata.taskID == task][['id', 'labeler', 'value', 'offset_from', 'offset_to', 'content']]\n",
    "    df_task = df_task.groupby(['id', 'labeler']).last().reset_index()\n",
    "\n",
    "    units = df_task.groupby('id').apply(group_offsets)\n",
    "    units = units[units.map(lambda x: len(x)>1)]\n",
    "    units_dict[task] = units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 42\n",
      "Do: 0.21428571428571427\n",
      "De: 0.4436701509872242\n",
      "n: 40\n",
      "Do: 0.3\n",
      "De: 0.9384615384615385\n",
      "n: 40\n",
      "Do: 0.3\n",
      "De: 0.7551282051282051\n",
      "n: 39\n",
      "Do: 0.4358974358974359\n",
      "De: 0.9608636977058029\n",
      "n: 9\n",
      "Do: 0.6666666666666666\n",
      "De: 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "kalphas_overlap_sim = {}\n",
    "for task in tasks:\n",
    "    ka = krippendorff_alpha(units_dict[task].to_dict(), lambda x, y: text_similarity_metric(x, y, 0, 0))\n",
    "    kalphas_overlap_sim[task] = ka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FACT': 0.5170157068062828,\n",
       " 'CAUSE': 0.680327868852459,\n",
       " 'QUANTITY': 0.6027164685908319,\n",
       " 'LOCATION_ORIGIN': 0.5463483146067416,\n",
       " 'DATE': 0.2941176470588236}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print Krippendorff's alpha score based on text selection overlap + text similarity\n",
    "# for a given label and for each NER task\n",
    "kalphas_overlap_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FACT': 0.5381727158948686,\n",
       " 'CAUSE': 0.36023622047244097,\n",
       " 'QUANTITY': 0.5375494071146245,\n",
       " 'LOCATION_ORIGIN': 0.3930555555555555,\n",
       " 'DATE': 0.08571428571428574}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print Krippendorff's alpha score based on text selection overlap\n",
    "# for a given label and for each NER task\n",
    "kalphas_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all metrics\n",
    "### First compute disagreement for overlap+similarity, then for labels but only on assets where there is overlap or similarity between selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data(subgroup):\n",
    "    offsets = []\n",
    "    for ix, row in subgroup.iterrows():\n",
    "        offsets.append((row['value'], row['offset_from'], row['offset_to'], row['content']))\n",
    "    return offsets\n",
    "\n",
    "tasks = ['FACT', 'CAUSE', 'QUANTITY', 'LOCATION_ORIGIN', 'DATE']\n",
    "\n",
    "units_dict = {}\n",
    "for task in tasks:\n",
    "    df_task = kilidata[kilidata.taskID == task][['id', 'labeler', 'value', 'offset_from', 'offset_to', 'content']]\n",
    "    df_task = df_task.groupby(['id', 'labeler']).last().reset_index()\n",
    "\n",
    "    units = df_task.groupby('id').apply(group_data)\n",
    "    units = units[units.map(lambda x: len(x)>1)]\n",
    "    units_dict[task] = units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(a, b):\n",
    "    score_label = text_similarity_metric(a[1:], b[1:])\n",
    "    score_class = metrics[task](a[0], b[0])\n",
    "    return (score_label + score_class)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 42\n",
      "Do: 0.32142857142857145\n",
      "De: 0.5882694541231127\n",
      "n: 40\n",
      "Do: 0.2\n",
      "De: 0.6974358974358974\n",
      "n: 40\n",
      "Do: 0.225\n",
      "De: 0.4717948717948718\n",
      "n: 39\n",
      "Do: 0.5769230769230769\n",
      "De: 0.8306342780026991\n",
      "n: 9\n",
      "Do: 0.4444444444444444\n",
      "De: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "kalphas_overlap_sim = {}\n",
    "for task in tasks:\n",
    "    ka = krippendorff_alpha(units_dict[task].to_dict(), eval_metric)\n",
    "    kalphas_overlap_sim[task] = ka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FACT': 0.45360315893385983,\n",
       " 'CAUSE': 0.713235294117647,\n",
       " 'QUANTITY': 0.5230978260869565,\n",
       " 'LOCATION_ORIGIN': 0.30544272948822104,\n",
       " 'DATE': 0.33333333333333337}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kalphas_overlap_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
